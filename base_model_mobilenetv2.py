# -*- coding: utf-8 -*-
"""From_Colab_Base_Model_AlexNet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QkAniFSsv04mcwvSAoBQ4jY51p6y69kq
"""

from google.colab import drive
drive.mount('/content/drive')

import tensorflow as tf
import os

base_dir = "/content/drive/MyDrive/Final_Project/images"

IMAGE_SIZE = 224
BATCH_SIZE = 64

datagen = tf.keras.preprocessing.image.ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2,
)

train_generator = datagen.flow_from_directory(
    base_dir,
    target_size=(IMAGE_SIZE, IMAGE_SIZE),
    batch_size=BATCH_SIZE,
    subset='training'
)

val_generator = datagen.flow_from_directory(
    base_dir,
    target_size=(IMAGE_SIZE, IMAGE_SIZE),
    batch_size=BATCH_SIZE,
    subset='validation'
)

print(train_generator.class_indices)
labels = '\n'.join(sorted(train_generator.class_indices.keys()))
labels
with open('labels.txt', 'w') as f:
  f.write(labels)

IMG_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, 3)

base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,
                                               include_top=False,
                                               weights='imagenet')

base_model.trainable = False

model = tf.keras.Sequential([    
                            base_model,
                                                        
                            tf.keras.layers.Flatten(),
                            tf.keras.layers.Dropout(0.2),
                            tf.keras.layers.Dense(64),
                            tf.keras.layers.Dense(32),
                            tf.keras.layers.Dense(17, activation="softmax")
])
model.summary()

model.compile(optimizer=tf.keras.optimizers.Adam(),
              loss="categorical_crossentropy",
              metrics=['accuracy'])

epochs = 5

history = model.fit(train_generator,
                    epochs = epochs,
                    validation_data=val_generator)

saved_model_dir = ''
tf.saved_model.save(model, saved_model_dir)

converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)
tflite_model = converter.convert()

with open('model.tflite', 'wb') as f:
  f.write(tflite_model)

from google.colab import files
files.download('model.tflite')
files.download('labels.txt')

from tensorflow import keras
from tensorflow.keras import layers, models

pip install visualkeras

import visualkeras

visualkeras.layered_view(model, legend=True, draw_volume=False)

visualkeras.layered_view(model, legend=True)

# Measure accuracy and loss after training

final_loss, final_accuracy = model.evaluate(val_generator)

print("Final loss: {:.2f}".format(final_loss))
print("Final accuracy: {:.2f}%".format(final_accuracy * 100))

import matplotlib.pylab as plt

# Visualize training process

plt.figure()
plt.ylabel("Loss (training and validation)")
plt.xlabel("Training Steps")
plt.ylim([0,2])
plt.plot(history.history["loss"])
plt.plot(history.history["val_loss"])

plt.figure()
plt.ylabel("Accuracy (training and validation)")
plt.xlabel("Training Steps")
plt.ylim([0,1])
plt.plot(history.history["accuracy"])
plt.plot(history.history["val_accuracy"])

import numpy as np

# Get images and labels batch from validation dataset generator
# Validation batch shape tells us that we have a batch of 32 images, with size and channels: 224x224x3.

val_image_batch, val_label_batch = next(iter(val_generator))
true_label_ids = np.argmax(val_label_batch, axis=-1)

print("Validation batch shape:", val_image_batch.shape)

#calculate predictions for the entire batch.

tf_model_predictions = model(val_image_batch)
print("Prediction results shape:", tf_model_predictions.shape)

import pandas as pd

dataset_labels = sorted(train_generator.class_indices.keys())

# Convert prediction results to Pandas dataframe, for better visualization

tf_pred_dataframe = pd.DataFrame(tf_model_predictions.numpy())
tf_pred_dataframe.columns = dataset_labels

print("Prediction results for the first elements")
tf_pred_dataframe.head()



predicted_ids = np.argmax(tf_model_predictions, axis=-1)
predicted_labels = predicted_ids

# Print images batch and labels predictions

plt.figure(figsize=(10,9))
plt.subplots_adjust(hspace=0.5)
for n in range(30):
  plt.subplot(6,5,n+1)
  plt.imshow(val_image_batch[n])
  color = "green" if predicted_ids[n] == true_label_ids[n] else "red"
  plt.title(predicted_labels[n], color=color)
  plt.axis('off')
_ = plt.suptitle("Model predictions (green: correct, red: incorrect)")

from PIL import Image
import numpy as np

#Load in Image we want to make a prediction on

img_path = '/content/drive/MyDrive/Final_Project/Test/images - 2022-02-19T154920.588.jpg'


#Preprocess image to make prediction on
img = Image.open(img_path)
# print(img)
img = img.resize((224,224))
npimg = np.array(img)
# npimg.expand_dims(1)
npimg2 = np.expand_dims(npimg, axis=0)
print(npimg2.shape)

predict_prob = model.predict(npimg2)

predict_classes=np.argmax(predict_prob,axis=1)
predict_classes



